{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "'''DATA CLEANING'''\n",
    "\n",
    "from calendar import day_abbr\n",
    "import requests\n",
    "import urllib\n",
    "import json\n",
    "import csv\n",
    "# f = open('Desktop/NextMunch/next-munch/json_files/cuisines.json')\n",
    "# data = json.load(f)\n",
    "# print(len(data))\n",
    "url2 = \"https://worldwide-restaurants.p.rapidapi.com/search\"\n",
    "\n",
    "dietary_reqs = ['Vegetarian Friendly', 'Vegan Options', 'Gluten Free Options', 'Halal', 'Kosher']\n",
    "#2nd page\n",
    "new_url = \"https://api.tripadvisor.com/api/internal/1.14/location/186338/restaurants?base_geocodes_on=citymaps&currency=GBP&is_restaurant_filters_v2=true&lang=en_US&limit=50&offset=50&restaurant_tagcategory_standalone=186338&supports_relevance=true\"\n",
    "\n",
    "headers = {\n",
    "\t\"content-type\": \"application/x-www-form-urlencoded\",\n",
    "\t\"X-RapidAPI-Key\": \"3b11ee2336msh5791c275fc5dbc6p11fa37jsn3cafb1ed4e82\",\n",
    "\t\"X-RapidAPI-Host\": \"worldwide-restaurants.p.rapidapi.com\"\n",
    "}\n",
    "restaurant_list = ['restaurants']\n",
    "address_list= ['address']\n",
    "category_list = ['category']\n",
    "cuisine_list = ['cuisine']\n",
    "dietary_list = ['dietary requirements']\n",
    "phone_list = ['phone No']\n",
    "price_list = ['price']\n",
    "index2 = 0\n",
    "# temp_list = []\n",
    "new_list = []\n",
    "\n",
    "def get_API_values(url, header, index):\n",
    "    print(index)\n",
    "    if index == 3:\n",
    "        f = open('APIvals.csv', 'w')\n",
    "        for i in range(len(restaurant_list)):\n",
    "                # string = '{'\n",
    "                string = f'{restaurant_list[i]}, {address_list[i]}, {category_list[i]}, {price_list[i]}, {phone_list[i]}, {cuisine_list[i]}, {dietary_list[i]}\\n'\n",
    "                # string = f'{dietary_list[i]}\\n'\n",
    "                # string += '},\\n'\n",
    "                f.write(string)\n",
    "                # f.write('\\n')\n",
    "        \n",
    "       \n",
    "        f.close()\n",
    "        # with open('APIvals.csv', 'a') as file:\n",
    "        #     writer = csv.writer(file)\n",
    "    \n",
    "        #     # for i in range(len(cuisine_list)):\n",
    "        #     #     string = '{'\n",
    "        #     #     string += f'\"restaurant\": \"{cuisine_list[i]}\", \"address\": \"{address_list[i]}\"'\n",
    "        #     #     string += '},'\n",
    "        #         # print(string)\n",
    "        #     writer.writerow(cuisine_list[0])\n",
    "        #     writer.writerow('\\n')\n",
    "\n",
    "    else:\n",
    "\n",
    "        payload = f\"offset={index}&language=en_UK&limit=20500&location_id=186338&currency=GBP\"\n",
    "        response = requests.request(\"POST\", url, data=payload, headers=header)\n",
    "        \n",
    "        data = json.loads(response.text)['results']['data']\n",
    "        for i in range(len(data)):\n",
    "            # index = str(i)\n",
    "            # print(data[index]['cuisine'])\n",
    "            restaurant = data[i]['name']\n",
    "            address = data[i]['address']\n",
    "            category = data[i]['category']['name']\n",
    "            cuisine = data[i]['cuisine']\n",
    "            try:\n",
    "                price = data[i]['price']\n",
    "                phone_number = data[i]['phone']\n",
    "            except KeyError:\n",
    "                price = data[i]['price_level']\n",
    "                phone_number = 'NULL'\n",
    "         \n",
    "            if restaurant not in restaurant_list:\n",
    "                address_list.append(address)\n",
    "                restaurant_list.append(restaurant)\n",
    "                category_list.append(category)\n",
    "                phone_list.append(phone_number)\n",
    "                price_list.append(price)\n",
    "                cuisine_temp_list = []\n",
    "                dietary_temp_list = []\n",
    "                for i in range(len(cuisine)-1):\n",
    "                  \n",
    "                    if cuisine[i]['name'] not in dietary_reqs:\n",
    "                        cuisine_temp_list.append(cuisine[i])\n",
    "                    else:\n",
    "                        dietary_temp_list.append(cuisine[i])\n",
    "\n",
    "                cuisine_list.append(cuisine_temp_list)\n",
    "                dietary_list.append(dietary_temp_list)\n",
    "                # temp_list = []\n",
    "            \n",
    "            \n",
    "                # for i in range(len(cuisine)):\n",
    "                #     temp[]\n",
    "                #     dietary_list.append(i['name'])\n",
    "                    # print(i['name'])\n",
    "                \n",
    "\n",
    "\n",
    "        get_API_values(url, header, index+1)\n",
    "\n",
    "\n",
    "get_API_values(url2, headers, index2)\n",
    "\n",
    "#     for cuisine in cuisines:\n",
    "\n",
    "#             cuisine_list.append(cuisine['name'])\n",
    "\n",
    "        # string=''\n",
    "    \n",
    "    # print('{cuisine: {csn}},').format(csn = cuisine_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 16 fields in line 3, saw 18\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPIvals.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/io/parsers/readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    580\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 581\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1255\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1253\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1254\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1255\u001b[0m     index, columns, col_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[1;32m   1256\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1257\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 225\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    226\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    227\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1960\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 16 fields in line 3, saw 18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"APIvals.csv\", on_bad_lines='skip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
